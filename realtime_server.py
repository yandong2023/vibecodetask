#!/usr/bin/env python3
"""
VibeCodeTask å®æ—¶ç›‘æ§æœåŠ¡å™¨
çœŸå®é›†æˆccusageå‘½ä»¤ï¼Œæä¾›å®æ—¶Tokenç›‘æ§å’Œä»»åŠ¡æ‰§è¡Œ
"""

import os
import json
import time
import subprocess
import threading
import shutil
from datetime import datetime
from http.server import HTTPServer, BaseHTTPRequestHandler
from urllib.parse import urlparse, parse_qs
import sqlite3
import webbrowser
from claude_executor import ClaudeExecutor

# ç®€å•æ—¥å¿—è¿½åŠ åˆ°æ–‡ä»¶ï¼ˆä¸æ›¿æ¢ç°æœ‰printï¼‰
def append_log(message: str):
    try:
        log_path = os.path.join(os.path.dirname(__file__), 'server.log')
        ts = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        with open(log_path, 'a', encoding='utf-8') as f:
            f.write(f"[{ts}] {message}\n")
    except Exception:
        pass

class TokenMonitor:
    """å®æ—¶Tokenç›‘æ§å™¨"""
    
    def __init__(self):
        self.cache = {}
        self.history_cache = {}
        self.last_update = 0
        self.last_history_update = 0
        self.cache_duration = 30  # 30ç§’ç¼“å­˜
        self.history_cache_duration = 300  # å†å²æ•°æ®5åˆ†é’Ÿç¼“å­˜
    
    def get_real_time_data(self):
        """è·å–å®æ—¶Tokenæ•°æ®"""
        now = time.time()
        
        # æ£€æŸ¥ç¼“å­˜
        if self.cache and (now - self.last_update) < self.cache_duration:
            return self.cache
        
        try:
            print("[TokenMonitor] è·å–å®æ—¶Tokenæ•°æ®...")
            
            # è§£æ ccusage å¯æ‰§è¡Œè·¯å¾„ä¸ç¯å¢ƒ
            ccusage_bin = self._resolve_ccusage()
            env = self._build_env()

            # è·å–ä»Šæ—¥ä½¿ç”¨æ•°æ®
            daily_result = subprocess.run([
                ccusage_bin, 'daily', '--json', '-s', datetime.now().strftime('%Y%m%d')
            ], capture_output=True, text=True, timeout=10, env=env)
            
            # è·å–æ´»è·ƒBlockæ•°æ®
            block_result = subprocess.run([
                ccusage_bin, 'blocks', '--json', '--active'
            ], capture_output=True, text=True, timeout=10, env=env)
            
            data = {'error': None}
            
            if daily_result.returncode == 0:
                daily_data = json.loads(daily_result.stdout)
                data['daily'] = daily_data
            else:
                data['daily'] = None
                data['error'] = f"Daily data error: {daily_result.stderr}"
            
            if block_result.returncode == 0:
                block_data = json.loads(block_result.stdout)
                data['blocks'] = block_data
            else:
                data['blocks'] = None
                if not data['error']:
                    data['error'] = f"Block data error: {block_result.stderr}"
            
            # å¤„ç†å’Œç¼“å­˜æ•°æ®
            processed_data = self._process_data(data)
            self.cache = processed_data
            self.last_update = now
            
            print(f"[TokenMonitor] æ•°æ®æ›´æ–°å®Œæˆï¼ŒTokenä½¿ç”¨: {processed_data.get('totalTokens', 0)}")
            return processed_data
            
        except subprocess.TimeoutExpired:
            error_data = self._get_error_data("ccusageå‘½ä»¤è¶…æ—¶")
            print("[TokenMonitor] ccusageå‘½ä»¤è¶…æ—¶")
            return error_data
        except Exception as e:
            error_data = self._get_error_data(f"è·å–æ•°æ®å¤±è´¥: {str(e)}")
            print(f"[TokenMonitor] é”™è¯¯: {e}")
            return error_data

    def _resolve_ccusage(self) -> str:
        """ä¼˜å…ˆä½¿ç”¨ç³»ç»Ÿ ccusageï¼Œæ‰¾ä¸åˆ°åˆ™å›é€€åˆ°æœ¬åœ° node_modules/.bin"""
        # 1) PATH ä¸­æŸ¥æ‰¾
        sys_path = shutil.which('ccusage')
        if sys_path:
            return sys_path
        # 2) æœ¬åœ° node_modules/.bin
        local_bin = os.path.join(os.path.dirname(__file__), 'node_modules', '.bin', 'ccusage')
        if os.name == 'nt':
            local_bin += '.cmd'
        if os.path.exists(local_bin):
            return local_bin
        # 3) å…œåº•ä»è¿”å›å‘½ä»¤åï¼ˆè®©é”™è¯¯ä¿¡æ¯æ›´ç›´è§‚ï¼‰
        return 'ccusage'

    def _build_env(self) -> dict:
        """æ‰©å±• PATHï¼ŒæŠŠæœ¬åœ° node_modules/.bin æ”¾åˆ°å‰é¢ï¼Œç¡®ä¿èƒ½æ‰¾åˆ°æœ¬åœ° ccusage"""
        env = os.environ.copy()
        project_bin = os.path.join(os.path.dirname(__file__), 'node_modules', '.bin')
        current_path = env.get('PATH', '')
        env['PATH'] = project_bin + os.pathsep + current_path
        return env
    
    def _process_data(self, raw_data):
        """å¤„ç†åŸå§‹æ•°æ®"""
        result = {
            'timestamp': datetime.now().isoformat(),
            'error': raw_data.get('error')
        }
        
        # å¤„ç†æ¯æ—¥æ•°æ®
        daily = raw_data.get('daily')
        if daily and daily.get('totals'):
            totals = daily['totals']
            result.update({
                'totalTokens': totals.get('totalTokens', 0),
                'totalCost': totals.get('totalCost', 0.0),
                'inputTokens': totals.get('inputTokens', 0),
                'outputTokens': totals.get('outputTokens', 0),
                'cacheCreationTokens': totals.get('cacheCreationTokens', 0),
                'cacheReadTokens': totals.get('cacheReadTokens', 0),
                'modelsUsed': daily['daily'][0].get('modelsUsed', []) if daily.get('daily') else []
            })
        else:
            result.update({
                'totalTokens': 0,
                'totalCost': 0.0,
                'inputTokens': 0,
                'outputTokens': 0,
                'cacheCreationTokens': 0,
                'cacheReadTokens': 0,
                'modelsUsed': []
            })
        
        # å¤„ç†Blockæ•°æ®
        blocks = raw_data.get('blocks')
        if blocks and blocks.get('blocks'):
            active_block = blocks['blocks'][0]
            result['blockInfo'] = {
                'isActive': active_block.get('isActive', False),
                'entries': active_block.get('entries', 0),
                'blockTokens': active_block.get('totalTokens', 0),
                'blockCost': active_block.get('costUSD', 0.0),
                'burnRate': active_block.get('burnRate', {}),
                'projection': active_block.get('projection', {}),
                'startTime': active_block.get('startTime'),
                'endTime': active_block.get('endTime')
            }
        else:
            result['blockInfo'] = {
                'isActive': False,
                'entries': 0,
                'blockTokens': 0,
                'blockCost': 0.0,
                'burnRate': {},
                'projection': {},
                'startTime': None,
                'endTime': None
            }
        
        # è®¡ç®—çŠ¶æ€
        total_tokens = result['totalTokens']
        if total_tokens < 500000:
            result['status'] = 'good'
        elif total_tokens < 1000000:
            result['status'] = 'warning'  
        else:
            result['status'] = 'critical'
        
        return result
    
    def _get_error_data(self, error_msg):
        """è¿”å›é”™è¯¯æ•°æ®"""
        return {
            'timestamp': datetime.now().isoformat(),
            'error': error_msg,
            'totalTokens': 0,
            'totalCost': 0.0,
            'inputTokens': 0,
            'outputTokens': 0,
            'cacheCreationTokens': 0,
            'cacheReadTokens': 0,
            'modelsUsed': [],
            'blockInfo': {
                'isActive': False,
                'entries': 0,
                'blockTokens': 0,
                'blockCost': 0.0,
                'burnRate': {},
                'projection': {}
            },
            'status': 'unknown'
        }
    
    def get_historical_data(self, days=30):
        """è·å–å†å²æ•°æ® (æœ€è¿‘Nå¤©)"""
        now = time.time()
        
        # æ£€æŸ¥å†å²æ•°æ®ç¼“å­˜
        cache_key = f"history_{days}"
        if (cache_key in self.history_cache and 
            (now - self.last_history_update) < self.history_cache_duration):
            return self.history_cache[cache_key]
        
        try:
            print(f"[TokenMonitor] è·å–æœ€è¿‘{days}å¤©å†å²æ•°æ®...")
            
            # è®¡ç®—èµ·å§‹æ—¥æœŸ
            from datetime import timedelta
            start_date = (datetime.now() - timedelta(days=days)).strftime('%Y%m%d')
            
            # æ‰§è¡Œccusageå†å²æŸ¥è¯¢ï¼ˆå¸¦è·¯å¾„è§£æä¸ç¯å¢ƒï¼‰
            ccusage_bin = self._resolve_ccusage()
            env = self._build_env()
            result = subprocess.run([
                ccusage_bin, '-s', start_date, '--json'
            ], capture_output=True, text=True, timeout=30, env=env)
            
            if result.returncode == 0:
                data = json.loads(result.stdout)
                processed_data = self._process_historical_data(data)
                
                # ç¼“å­˜ç»“æœ
                self.history_cache[cache_key] = processed_data
                self.last_history_update = now
                
                print(f"[TokenMonitor] å†å²æ•°æ®è·å–å®Œæˆï¼Œå…±{len(data.get('daily', []))}å¤©")
                return processed_data
            else:
                error_msg = f"è·å–å†å²æ•°æ®å¤±è´¥: {result.stderr}"
                print(f"[TokenMonitor] {error_msg}")
                return {'error': error_msg, 'daily': [], 'totals': {}}
                
        except subprocess.TimeoutExpired:
            error_msg = "è·å–å†å²æ•°æ®è¶…æ—¶"
            print(f"[TokenMonitor] {error_msg}")
            return {'error': error_msg, 'daily': [], 'totals': {}}
        except Exception as e:
            error_msg = f"è·å–å†å²æ•°æ®å¼‚å¸¸: {str(e)}"
            print(f"[TokenMonitor] {error_msg}")
            return {'error': error_msg, 'daily': [], 'totals': {}}
    
    def _process_historical_data(self, raw_data):
        """å¤„ç†å†å²æ•°æ®"""
        result = {
            'timestamp': datetime.now().isoformat(),
            'error': None,
            'daily': raw_data.get('daily', []),
            'totals': raw_data.get('totals', {}),
            'summary': {}
        }
        
        # è®¡ç®—æ±‡æ€»ä¿¡æ¯
        daily_data = raw_data.get('daily', [])
        if daily_data:
            total_days = len(daily_data)
            avg_tokens = sum(day.get('totalTokens', 0) for day in daily_data) / total_days if total_days > 0 else 0
            avg_cost = sum(day.get('totalCost', 0) for day in daily_data) / total_days if total_days > 0 else 0
            
            # æ‰¾å‡ºä½¿ç”¨é‡æœ€é«˜å’Œæœ€ä½çš„å¤©
            max_day = max(daily_data, key=lambda x: x.get('totalTokens', 0), default={})
            min_day = min(daily_data, key=lambda x: x.get('totalTokens', 0), default={})
            
            # è®¡ç®—è¶‹åŠ¿ï¼ˆæœ€è¿‘7å¤© vs å‰é¢7å¤©çš„å¹³å‡å€¼ï¼‰
            recent_7_days = daily_data[-7:] if len(daily_data) >= 7 else daily_data
            previous_7_days = daily_data[-14:-7] if len(daily_data) >= 14 else []
            
            recent_avg = sum(day.get('totalTokens', 0) for day in recent_7_days) / len(recent_7_days) if recent_7_days else 0
            previous_avg = sum(day.get('totalTokens', 0) for day in previous_7_days) / len(previous_7_days) if previous_7_days else recent_avg
            
            trend = 'increasing' if recent_avg > previous_avg * 1.1 else ('decreasing' if recent_avg < previous_avg * 0.9 else 'stable')
            
            result['summary'] = {
                'totalDays': total_days,
                'averageTokensPerDay': round(avg_tokens),
                'averageCostPerDay': round(avg_cost, 2),
                'maxUsageDay': {
                    'date': max_day.get('date', ''),
                    'tokens': max_day.get('totalTokens', 0),
                    'cost': max_day.get('totalCost', 0)
                },
                'minUsageDay': {
                    'date': min_day.get('date', ''),
                    'tokens': min_day.get('totalTokens', 0),
                    'cost': min_day.get('totalCost', 0)
                },
                'recentTrend': trend,
                'recentAverage': round(recent_avg),
                'previousAverage': round(previous_avg)
            }
        
        return result


class TaskManager:
    """ä»»åŠ¡ç®¡ç†å™¨"""
    
    def __init__(self, db_path='tasks.db'):
        self.db_path = db_path
        self.claude_executor = ClaudeExecutor()
        self.init_database()
    
    def init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS tasks (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                description TEXT NOT NULL,
                type TEXT DEFAULT 'immediate',
                status TEXT DEFAULT 'pending',
                scheduled_time TEXT,
                created_at TEXT,
                updated_at TEXT,
                estimated_tokens INTEGER,
                actual_tokens INTEGER,
                result TEXT,
                task_directory TEXT,
                files_created TEXT
            )
        ''')
        conn.commit()
        conn.close()
    
    def add_task(self, description, task_type='immediate', scheduled_time=None):
        """æ·»åŠ ä»»åŠ¡"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        now = datetime.now().isoformat()
        estimated_tokens = len(description) * 4  # ç®€å•ä¼°ç®—
        
        cursor.execute('''
            INSERT INTO tasks (description, type, status, scheduled_time, created_at, updated_at, estimated_tokens)
            VALUES (?, ?, 'pending', ?, ?, ?, ?)
        ''', (description, task_type, scheduled_time, now, now, estimated_tokens))
        
        task_id = cursor.lastrowid
        conn.commit()
        conn.close()
        
        print(f"[TaskManager] ä»»åŠ¡å·²æ·»åŠ  ID:{task_id} - {description[:50]}...")
        return task_id
    
    def get_all_tasks(self):
        """è·å–æ‰€æœ‰ä»»åŠ¡"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('SELECT * FROM tasks ORDER BY created_at DESC')
        rows = cursor.fetchall()
        conn.close()
        
        tasks = []
        for row in rows:
            tasks.append({
                'id': row[0],
                'description': row[1],
                'type': row[2],
                'status': row[3],
                'scheduledTime': row[4],
                'createdAt': row[5],
                'updatedAt': row[6],
                'estimatedTokens': row[7],
                'actualTokens': row[8],
                'result': row[9],
                'taskDirectory': row[10] if len(row) > 10 else None,
                'filesCreated': json.loads(row[11]) if len(row) > 11 and row[11] else []
            })
        
        return tasks
    
    def update_task_status(self, task_id, status, result=None, task_directory=None, files_created=None):
        """æ›´æ–°ä»»åŠ¡çŠ¶æ€"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        now = datetime.now().isoformat()
        files_json = json.dumps(files_created) if files_created else None
        
        cursor.execute('''
            UPDATE tasks SET status = ?, result = ?, task_directory = ?, files_created = ?, updated_at = ?
            WHERE id = ?
        ''', (status, result, task_directory, files_json, now, task_id))
        
        conn.commit()
        conn.close()
        
        print(f"[TaskManager] ä»»åŠ¡çŠ¶æ€æ›´æ–° ID:{task_id} -> {status}")
        append_log(f"Task {task_id} status -> {status}")
        if task_directory:
            print(f"[TaskManager] æ–‡ä»¶ç”Ÿæˆç›®å½•: {task_directory}")
            append_log(f"Task {task_id} dir: {task_directory}")

    def recover_stuck_tasks(self, max_minutes: int = 10):
        """å°†é•¿æ—¶é—´å¤„äºrunningçŠ¶æ€çš„ä»»åŠ¡è‡ªåŠ¨æ ‡è®°ä¸ºfailed"""
        try:
            threshold = (datetime.now() - timedelta(minutes=max_minutes)).isoformat()
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('''
                UPDATE tasks
                SET status = 'failed', result = COALESCE(result, '') || '[è‡ªåŠ¨æ¢å¤] è¿è¡Œè¶…æ—¶ï¼Œå·²æ ‡è®°å¤±è´¥', updated_at = ?
                WHERE status = 'running' AND updated_at < ?
            ''', (datetime.now().isoformat(), threshold))
            affected = cursor.rowcount
            conn.commit()
            conn.close()
            if affected:
                msg = f"[TaskManager] è‡ªåŠ¨æ¢å¤ï¼šæ ‡è®° {affected} ä¸ªå¡ä½çš„runningä»»åŠ¡ä¸ºfailed"
                print(msg)
                append_log(msg)
        except Exception as e:
            msg = f"[TaskManager] è‡ªåŠ¨æ¢å¤å¤±è´¥: {e}"
            print(msg)
            append_log(msg)
    
    def delete_task(self, task_id):
        """åˆ é™¤ä»»åŠ¡"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('DELETE FROM tasks WHERE id = ?', (task_id,))
        conn.commit()
        conn.close()
        print(f"[TaskManager] ä»»åŠ¡å·²åˆ é™¤ ID:{task_id}")
    
    def execute_task_with_claude(self, task_id):
        """ä½¿ç”¨Claude Codeæ‰§è¡Œä»»åŠ¡"""
        # è·å–ä»»åŠ¡ä¿¡æ¯
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('SELECT description FROM tasks WHERE id = ?', (task_id,))
        result = cursor.fetchone()
        conn.close()
        
        if not result:
            return {'success': False, 'error': 'ä»»åŠ¡ä¸å­˜åœ¨'}
        
        description = result[0]
        
        # æ›´æ–°çŠ¶æ€ä¸ºæ‰§è¡Œä¸­
        self.update_task_status(task_id, 'running')
        
        try:
            print(f"[TaskManager] å¼€å§‹æ‰§è¡Œä»»åŠ¡ {task_id}: {description[:50]}...")
            append_log(f"Task {task_id} start: {description[:50]}...")

            # åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œä»¥å®ç°æ•´ä½“è¶…æ—¶æ§åˆ¶
            import threading
            result_holder = {'value': None}

            def run_exec():
                try:
                    result_holder['value'] = self.claude_executor.execute_task(task_id, description)
                except Exception as e:
                    result_holder['value'] = {'success': False, 'error': f'æ‰§è¡Œå¼‚å¸¸: {e}'}

            t = threading.Thread(target=run_exec)
            t.daemon = True
            t.start()
            t.join(timeout=120)  # æ€»ä½“è¶…æ—¶120ç§’

            if t.is_alive():
                # è¶…æ—¶å¤„ç†
                timeout_msg = 'æ‰§è¡Œè¶…æ—¶ï¼ˆè¶…è¿‡120ç§’ï¼‰'
                self.update_task_status(task_id, 'failed', timeout_msg)
                append_log(f"Task {task_id} timeout")
                print(f"[TaskManager] ä»»åŠ¡ {task_id} è¶…æ—¶: {timeout_msg}")
                return {'success': False, 'error': timeout_msg}

            execution_result = result_holder['value'] or {'success': False, 'error': 'æœªçŸ¥é”™è¯¯'}

            if execution_result.get('success'):
                self.update_task_status(
                    task_id,
                    'completed',
                    execution_result.get('report'),
                    execution_result.get('task_dir'),
                    execution_result.get('files_created')
                )
                print(f"[TaskManager] ä»»åŠ¡ {task_id} æ‰§è¡ŒæˆåŠŸ")
                append_log(f"Task {task_id} completed")
                return execution_result
            else:
                self.update_task_status(
                    task_id,
                    'failed',
                    execution_result.get('error', 'æœªçŸ¥é”™è¯¯')
                )
                print(f"[TaskManager] ä»»åŠ¡ {task_id} æ‰§è¡Œå¤±è´¥: {execution_result.get('error')}")
                append_log(f"Task {task_id} failed: {execution_result.get('error')}")
                return execution_result

        except Exception as e:
            error_msg = f"æ‰§è¡Œä»»åŠ¡æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}"
            self.update_task_status(task_id, 'failed', error_msg)
            print(f"[TaskManager] ä»»åŠ¡ {task_id} å¼‚å¸¸: {error_msg}")
            append_log(f"Task {task_id} exception: {error_msg}")
            return {'success': False, 'error': error_msg}
    
    def get_workspace_info(self):
        """è·å–å·¥ä½œåŒºä¿¡æ¯"""
        return self.claude_executor.get_workspace_info()


class RealtimeHandler(BaseHTTPRequestHandler):
    """HTTPè¯·æ±‚å¤„ç†å™¨"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
    
    def do_GET(self):
        """å¤„ç†GETè¯·æ±‚"""
        path = self.path.split('?')[0]
        
        if path == '/' or path == '/index.html':
            self.serve_html()
        elif path == '/api/token-status':
            self.get_token_status()
        elif path == '/api/tasks':
            self.get_tasks()
        elif path == '/api/workspace':
            self.get_workspace()
        elif path == '/api/live':
            self.serve_live_updates()
        elif path == '/api/history':
            self.get_history()
        elif path.startswith('/api/history/'):
            # æ”¯æŒ /api/history/30 è¿™æ ·çš„è·¯å¾„æŒ‡å®šå¤©æ•°
            try:
                days = int(path.split('/')[-1])
                self.get_history(days)
            except ValueError:
                self.send_error(400, "Invalid days parameter")
        else:
            self.send_error(404)
    
    def do_POST(self):
        """å¤„ç†POSTè¯·æ±‚"""
        path = self.path
        content_length = int(self.headers['Content-Length'])
        post_data = self.rfile.read(content_length).decode('utf-8')
        
        try:
            data = json.loads(post_data) if post_data else {}
        except:
            data = {}
        
        if path == '/api/add-task':
            self.add_task(data)
        elif path == '/api/update-task':
            self.update_task(data)
        elif path == '/api/delete-task':
            self.delete_task(data)
        elif path == '/api/execute-task':
            self.execute_task(data)
        else:
            self.send_error(404)
    
    def serve_html(self):
        """æä¾›HTMLç•Œé¢"""
        html_path = os.path.join(os.path.dirname(__file__), 'realtime_interface.html')
        
        if os.path.exists(html_path):
            with open(html_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æ›¿æ¢APIè°ƒç”¨ä¸ºçœŸå®ç«¯ç‚¹
            content = content.replace(
                'async function refreshTokenStatus() {',
                '''async function refreshTokenStatus() {
            try {
                const response = await fetch('/api/token-status');
                const data = await response.json();
                updateTokenDisplay(data);
            } catch (error) {
                console.error('è·å–TokençŠ¶æ€å¤±è´¥:', error);
            }
        }
        
        async function refreshTokenStatus_old() {'''
            )
            
            self.send_response(200)
            self.send_header('Content-Type', 'text/html; charset=utf-8')
            self.end_headers()
            self.wfile.write(content.encode('utf-8'))
        else:
            self.send_error(404, "HTMLæ–‡ä»¶æœªæ‰¾åˆ°")
    
    def get_token_status(self):
        """è·å–TokençŠ¶æ€"""
        token_data = token_monitor.get_real_time_data()
        self.send_json_response(token_data)
    
    def get_tasks(self):
        """è·å–ä»»åŠ¡åˆ—è¡¨"""
        tasks = task_manager.get_all_tasks()
        self.send_json_response({'tasks': tasks})
    
    def get_workspace(self):
        """è·å–å·¥ä½œåŒºä¿¡æ¯"""
        workspace_info = task_manager.get_workspace_info()
        self.send_json_response(workspace_info)
    
    def get_history(self, days=30):
        """è·å–å†å²ä½¿ç”¨æ•°æ®"""
        try:
            history_data = token_monitor.get_historical_data(days)
            self.send_json_response(history_data)
        except Exception as e:
            print(f"[RealtimeHandler] è·å–å†å²æ•°æ®å¤±è´¥: {e}")
            self.send_json_response({
                'error': f'è·å–å†å²æ•°æ®å¤±è´¥: {str(e)}',
                'daily': [],
                'totals': {}
            }, 500)
    
    def add_task(self, data):
        """æ·»åŠ ä»»åŠ¡"""
        description = data.get('description', '')
        task_type = data.get('type', 'immediate')
        scheduled_time = data.get('scheduledTime')
        
        if not description:
            self.send_json_response({'error': 'ä»»åŠ¡æè¿°ä¸èƒ½ä¸ºç©º'}, 400)
            return
        
        task_id = task_manager.add_task(description, task_type, scheduled_time)
        self.send_json_response({'success': True, 'taskId': task_id})
    
    def update_task(self, data):
        """æ›´æ–°ä»»åŠ¡"""
        task_id = data.get('taskId')
        status = data.get('status')
        result = data.get('result')
        
        if not task_id:
            self.send_json_response({'error': 'ä»»åŠ¡IDä¸èƒ½ä¸ºç©º'}, 400)
            return
        
        task_manager.update_task_status(task_id, status, result)
        self.send_json_response({'success': True})
    
    def delete_task(self, data):
        """åˆ é™¤ä»»åŠ¡"""
        task_id = data.get('taskId')
        
        if not task_id:
            self.send_json_response({'error': 'ä»»åŠ¡IDä¸èƒ½ä¸ºç©º'}, 400)
            return
        
        task_manager.delete_task(task_id)
        self.send_json_response({'success': True})
    
    def execute_task(self, data):
        """æ‰§è¡Œä»»åŠ¡"""
        task_id = data.get('taskId')
        
        if not task_id:
            self.send_json_response({'error': 'ä»»åŠ¡IDä¸èƒ½ä¸ºç©º'}, 400)
            return
        
        # åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œä»»åŠ¡ï¼Œé¿å…é˜»å¡HTTPå“åº”
        def execute_in_background():
            try:
                result = task_manager.execute_task_with_claude(task_id)
                print(f"[RealtimeHandler] ä»»åŠ¡ {task_id} æ‰§è¡Œå®Œæˆ: {result.get('success', False)}")
            except Exception as e:
                print(f"[RealtimeHandler] ä»»åŠ¡ {task_id} æ‰§è¡Œå¼‚å¸¸: {e}")
        
        execution_thread = threading.Thread(target=execute_in_background)
        execution_thread.daemon = True
        execution_thread.start()
        
        self.send_json_response({
            'success': True, 
            'message': f'ä»»åŠ¡ {task_id} å·²å¼€å§‹æ‰§è¡Œï¼Œè¯·åˆ·æ–°æŸ¥çœ‹è¿›åº¦'
        })
    
    def serve_live_updates(self):
        """æä¾›å®æ—¶æ›´æ–°æµ"""
        self.send_response(200)
        self.send_header('Content-Type', 'text/event-stream')
        self.send_header('Cache-Control', 'no-cache')
        self.send_header('Connection', 'keep-alive')
        self.send_header('Access-Control-Allow-Origin', '*')
        self.end_headers()
        
        # å‘é€åˆå§‹æ•°æ®
        token_data = token_monitor.get_real_time_data()
        self.wfile.write(f"data: {json.dumps(token_data)}\n\n".encode('utf-8'))
        self.wfile.flush()
    
    def send_json_response(self, data, status_code=200):
        """å‘é€JSONå“åº”"""
        response = json.dumps(data, ensure_ascii=False, indent=2)
        
        self.send_response(status_code)
        self.send_header('Content-Type', 'application/json; charset=utf-8')
        self.send_header('Access-Control-Allow-Origin', '*')
        self.end_headers()
        self.wfile.write(response.encode('utf-8'))
    
    def log_message(self, format, *args):
        """è‡ªå®šä¹‰æ—¥å¿—"""
        print(f"[{datetime.now().strftime('%H:%M:%S')}] {format % args}")


class TaskScheduler:
    """ä»»åŠ¡è°ƒåº¦å™¨ - è‡ªåŠ¨æ£€æŸ¥å’Œæ‰§è¡Œå®šæ—¶ä»»åŠ¡"""
    
    def __init__(self, task_manager):
        self.task_manager = task_manager
        self.running = False
        self.check_interval = 30  # 30ç§’æ£€æŸ¥ä¸€æ¬¡
    
    def start(self):
        """å¯åŠ¨è°ƒåº¦å™¨"""
        if self.running:
            return
        
        self.running = True
        
        def scheduler_loop():
            print("â° ä»»åŠ¡è°ƒåº¦å™¨å¯åŠ¨ï¼Œæ¯30ç§’æ£€æŸ¥ä¸€æ¬¡å¾…æ‰§è¡Œä»»åŠ¡")
            
            while self.running:
                try:
                    self.check_and_execute_tasks()
                    time.sleep(self.check_interval)
                except Exception as e:
                    print(f"[TaskScheduler] è°ƒåº¦å™¨é”™è¯¯: {e}")
                    time.sleep(self.check_interval)
        
        scheduler_thread = threading.Thread(target=scheduler_loop)
        scheduler_thread.daemon = True
        scheduler_thread.start()
    
    def stop(self):
        """åœæ­¢è°ƒåº¦å™¨"""
        self.running = False
        print("ğŸ›‘ ä»»åŠ¡è°ƒåº¦å™¨å·²åœæ­¢")
    
    def check_and_execute_tasks(self):
        """æ£€æŸ¥å¹¶æ‰§è¡Œåˆ°æœŸçš„ä»»åŠ¡"""
        now = datetime.now()
        
        # è·å–æ‰€æœ‰å¾…æ‰§è¡Œçš„å®šæ—¶ä»»åŠ¡
        conn = sqlite3.connect(self.task_manager.db_path)
        cursor = conn.cursor()
        cursor.execute('''
            SELECT id, description, scheduled_time 
            FROM tasks 
            WHERE status = 'pending' AND type = 'scheduled' AND scheduled_time IS NOT NULL
        ''')
        pending_tasks = cursor.fetchall()
        conn.close()
        
        executed_count = 0
        
        for task_id, description, scheduled_time_str in pending_tasks:
            try:
                # è§£æé¢„å®šæ—¶é—´
                scheduled_time = datetime.fromisoformat(scheduled_time_str.replace('Z', '+00:00'))
                scheduled_time = scheduled_time.replace(tzinfo=None)  # ç§»é™¤æ—¶åŒºä¿¡æ¯ï¼Œä½¿ç”¨æœ¬åœ°æ—¶é—´
                
                # æ£€æŸ¥æ˜¯å¦åˆ°æœŸï¼ˆå…è®¸30ç§’çš„è¯¯å·®ï¼‰
                if now >= scheduled_time:
                    print(f"â° æ‰§è¡Œå®šæ—¶ä»»åŠ¡ {task_id}: {description[:50]}...")
                    
                    # åœ¨åå°çº¿ç¨‹æ‰§è¡Œä»»åŠ¡
                    def execute_scheduled_task():
                        try:
                            result = self.task_manager.execute_task_with_claude(task_id)
                            status = "âœ… æˆåŠŸ" if result.get('success') else "âŒ å¤±è´¥"
                            print(f"[TaskScheduler] ä»»åŠ¡ {task_id} æ‰§è¡Œå®Œæˆ: {status}")
                        except Exception as e:
                            print(f"[TaskScheduler] ä»»åŠ¡ {task_id} æ‰§è¡Œå¼‚å¸¸: {e}")
                    
                    execution_thread = threading.Thread(target=execute_scheduled_task)
                    execution_thread.daemon = True
                    execution_thread.start()
                    
                    executed_count += 1
                    
            except Exception as e:
                print(f"[TaskScheduler] è§£æä»»åŠ¡ {task_id} æ—¶é—´å¤±è´¥: {e}")
        
        if executed_count > 0:
            print(f"[TaskScheduler] æœ¬æ¬¡æ£€æŸ¥æ‰§è¡Œäº† {executed_count} ä¸ªå®šæ—¶ä»»åŠ¡")


def main():
    """ä¸»å‡½æ•°"""
    global token_monitor, task_manager, task_scheduler
    
    print("ğŸš€ å¯åŠ¨ VibeCodeTask å®æ—¶ç›‘æ§æœåŠ¡å™¨...")
    
    # åˆå§‹åŒ–ç»„ä»¶
    token_monitor = TokenMonitor()
    task_manager = TaskManager()
    # æœåŠ¡å¯åŠ¨æ—¶è‡ªåŠ¨æ¢å¤å¡ä½çš„ä»»åŠ¡
    try:
        from datetime import timedelta
        task_manager.recover_stuck_tasks(max_minutes=10)
    except Exception as e:
        print(f"[Main] æ¢å¤å¡ä½ä»»åŠ¡å¤±è´¥: {e}")
        append_log(f"Recover stuck tasks failed: {e}")
    task_scheduler = TaskScheduler(task_manager)
    
    PORT = 8080
    server = HTTPServer(('localhost', PORT), RealtimeHandler)
    
    print(f"ğŸ“± æœåŠ¡å™¨è¿è¡Œåœ¨: http://localhost:{PORT}")
    print(f"ğŸ’¾ ä»»åŠ¡æ•°æ®åº“: {task_manager.db_path}")
    print("ğŸ” å¼€å§‹å®æ—¶ç›‘æ§Tokenä½¿ç”¨æƒ…å†µ...")
    
    # å¯åŠ¨ä»»åŠ¡è°ƒåº¦å™¨
    task_scheduler.start()
    
    # è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨
    def open_browser():
        time.sleep(1)
        webbrowser.open(f'http://localhost:{PORT}')
    
    browser_thread = threading.Thread(target=open_browser)
    browser_thread.daemon = True
    browser_thread.start()
    
    try:
        server.serve_forever()
    except KeyboardInterrupt:
        print("\nğŸ›‘ æœåŠ¡å™¨å·²åœæ­¢")
        task_scheduler.stop()


if __name__ == "__main__":
    main()